{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Resources on Stochastic Gradient Descent"
      ],
      "metadata": {
        "id": "GR6x2V8BgdDM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "990453b1"
      },
      "source": [
        "from GFG :\n",
        "\n",
        "[Stochastic Gradient Descent:](https://www.geeksforgeeks.org/machine-learning/ml-stochastic-gradient-descent-sgd/)\n",
        "\n",
        "And a Medium article :\n",
        "\n",
        "[Stochastic Gradient Descent:](https://mohitmishra786687.medium.com/stochastic-gradient-descent-a-basic-explanation-cbddc63f08e0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 1\n"
      ],
      "metadata": {
        "id": "JOFl0t--Zhxg"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a84c921a"
      },
      "source": [
        "How does the learning rate affect the convergence of Stochastic Gradient Descent, and what are some common strategies for choosing or adapting the learning rate during training?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#  Question 2"
      ],
      "metadata": {
        "id": "9cG-zPR3Xgfx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`Gradient Descent vs Stochastic Gradient Descent`\n",
        "\n",
        "Using the same preprocessed dataset from Question 2 from assignment-2'1, do the following:\n",
        "\n",
        "a) Train a Linear Regression model using Batch Gradient Descent (GD)\n",
        "\n",
        "b) Train a Linear Regression model using Stochastic Gradient Descent (SGD)\n",
        "\n",
        "c) Choose suitable values for learning rate and number of epochs.\n",
        "\n",
        "d) Predict house prices for the test dataset using both models.\n",
        "\n",
        "e) Evaluate both models using:\n",
        "Mean Squared Error (MSE) / R² Score\n",
        "\n",
        "f) Print the evaluation results of GD and SGD in a clear comparison format.\n",
        "\n",
        "g) Change the learning rate and epochs of the SGD model and observe how the performance changes.\n",
        "\n",
        "h) Explain why does the SGD path behave so erratically compared to the GD path, and despite this \"noise,\" why might SGD be preferred for very large datasets?"
      ],
      "metadata": {
        "id": "SshnjcyDW5mt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 3"
      ],
      "metadata": {
        "id": "DjQrDrC-Qgbp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decision Trees\n"
      ],
      "metadata": {
        "id": "M8w1SrPMEOnO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Theoretical and Numerical Questions\n",
        "\n",
        "a) Is a **Decision Tree** a supervised or unsupervised learning algorithm?  \n",
        "Give a brief explanation.\n",
        "\n",
        "b) What is **entropy** in the context of decision trees?\n",
        "\n",
        "c) What does **reduction in entropy** signify when a node is split in a decision tree?\n",
        "\n",
        "d) You are given a dataset consisting of **10 data points**, each having:\n",
        "- A class label (+ or −)\n",
        "- A 2D feature vector $(x, y)$\n",
        "\n",
        "All data points are initially present at the **root node** of a decision tree.\n",
        "\n",
        "A **decision stump** (depth = 1 decision tree) is to be learned at the root using the **entropy reduction principle**.\n",
        "\n",
        "**Allowed split questions:**\n",
        "\n",
        "\n",
        "- ($x \\le -2$?)\n",
        "- ($x \\le 2$?)\n",
        "- ($y \\le 2$?)\n",
        "\n",
        "**Assumptions:**\n",
        "- All logarithms are **base 2**\n",
        "\n",
        "\n",
        "- $\\log_2 3 = 1.58$\n",
        "- $\\log_2 5 = 2.32$\n",
        "\n",
        "- Give answers **correct to at least 2 decimal places**\n",
        "\n",
        "|S.No. | Class | (x, y) |\n",
        "|----|-------|--------|\n",
        "| 1  | − | (−3, 0) |\n",
        "| 2  | + | (3, 3) |\n",
        "| 3  | + | (1, 1) |\n",
        "| 4  | + | (1, −1) |\n",
        "| 5  | + | (−1, 1) |\n",
        "| 6  | + | (−1, −1) |\n",
        "| 7  | − | (1, 5) |\n",
        "| 8  | − | (1, 3) |\n",
        "| 9  | − | (−1, 5) |\n",
        "| 10 | − | (−1, 3) |\n",
        "\n",
        "\n",
        "Answer the following:\n",
        "1. Compute the **entropy of the root node**\n",
        "2. Compute the **entropy of the two child nodes** for each allowed split\n",
        "3. Compute the **reduction in entropy** for each split\n",
        "4. Identify **which split should be chosen** based on maximum entropy reduction\n",
        "\n"
      ],
      "metadata": {
        "id": "0r-F4bUvQ43J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Coding Question (Decision Tree using Iris Dataset)\n",
        "\n",
        "Write a Python program to **train and visualize a Decision Tree classifier** using the **Iris dataset**.\n",
        "\n",
        "Your code should:\n",
        "- Load the Iris dataset from `sklearn.datasets`\n",
        "- Split the data into **70% training** and **30% testing** sets\n",
        "- Train a Decision Tree classifier\n",
        "- Plot the learned decision tree with appropriate **feature names** and **class labels**\n"
      ],
      "metadata": {
        "id": "fpw9mvJtQ8Ox"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 4"
      ],
      "metadata": {
        "id": "QxR0Q0j2RC1Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Support Vector Machines (SVM)\n"
      ],
      "metadata": {
        "id": "dmlSugnUKMNX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 Theoretical\n",
        "\n",
        "a) Is a **Support Vector Machine (SVM)** a supervised or unsupervised learning algorithm?  \n",
        "Give a brief explanation.\n",
        "\n",
        "b) What is a **margin** in SVM?  \n",
        "Why does SVM aim to maximize the margin?\n",
        "\n",
        "c) What are **support vectors**?  \n",
        "Why are they important in defining the decision boundary?\n",
        "\n",
        "d) What is the purpose of a **kernel function** in SVM?  \n",
        "Name any two commonly used kernel functions.\n",
        "\n"
      ],
      "metadata": {
        "id": "1v88D6hCRLcJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2 Conceptual\n",
        "\n",
        "a) In a linearly separable dataset, how does SVM choose the **optimal separating hyperplane**?\n",
        "\n",
        "b) What happens when the data is **not linearly separable**?  \n",
        "Briefly explain how SVM handles this situation.\n",
        "\n",
        "c) What is the role of the **regularization parameter `C`** in SVM?  \n",
        "What happens when `C` is:\n",
        "- Very large  \n",
        "- Very small  "
      ],
      "metadata": {
        "id": "ryZVthcqROUl"
      }
    }
  ]
}